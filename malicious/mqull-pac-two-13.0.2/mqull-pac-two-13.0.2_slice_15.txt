function tokenize = function tokenize( selector, parseOnly ) {
	var matched, match, tokens, type,
		soFar, groups, preFilters,
		cached = tokenCache[ selector + " " ];

	if ( cached ) {
		return parseOnly ? 0 : cached.slice( 0 );
	}

	soFar = selector;
	groups = [];
	preFilters = Expr.preFilter;

	while ( soFar ) {

		// Comma and first run
		if ( !matched || ( match = rcomma.exec( soFar ) ) ) {
			if ( match ) {

				// Don't consume trailing commas as valid
				soFar = soFar.slice( match[ 0 ].length ) || soFar;
			}
			groups.push( ( tokens = [] ) );
		}

		matched = false;

		// Combinators
		if ( ( match = rcombinators.exec( soFar ) ) ) {
			matched = match.shift();
			tokens.push( {
				value: matched,

				// Cast descendant combinators to space
				type: match[ 0 ].replace( rtrim, " " )
			} );
			soFar = soFar.slice( matched.length );
		}

		// Filters
		for ( type in Expr.filter ) {
			if ( ( match = matchExpr[ type ].exec( soFar ) ) && ( !preFilters[ t...
var cached = tokenCache[ selector + " " ]
soFar = selector
__ecma.Array.factory()
preFilters = Expr.preFilter
!matched || ( match = rcomma.exec( soFar ) )
soFar = soFar.slice( match[ 0 ].length ) || soFar
groups.push( ( tokens = [] ) )
matched = false
match = rcombinators.exec( soFar )
matched = match.shift()
tokens.push( {
				value: matched,

				// Cast descendant combinators to space
				type: match[ 0 ].replace( rtrim, " " )
			} )
_tmp_110.value = matched
_tmp_110.type = match[ 0 ].replace( rtrim, " " )
soFar = soFar.slice( matched.length )
_iterator_20 = <operator>.iterator(Expr.filter)
( match = matchExpr[ type ].exec( soFar ) ) && ( !preFilters[ type ] ||
				( match = preFilters[ type ]( match ) ) )
match = preFilters[ type ]( match )
matched = match.shift()
tokens.push( {
					value: matched,
					type: type,
					matches: match
				} )
_tmp_113.value = matched
_tmp_113.type = type
_tmp_113.matches = match
soFar = soFar.slice( matched.length )
!matched
